{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification to detect stress source type\n",
    "Classes:\n",
    "- verticillium\n",
    "- cycloconium, \n",
    "- unidentified_stress \n",
    "- healthy\n",
    "\n",
    "Steps we need to follow:\n",
    "- set a threshold to determine if a sample will be considered stressed (based on previous analysis we select 5%)\n",
    "- check which factor provides the highest stress percentage (eg. Verticillium = 5 and is the greatest value between the three recorded sources) and label the sample as Vert\n",
    "- apply multiclass classification on the created columns as created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Load Libraries and the initial datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection as skl\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn import metrics as skm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sampling_data = pd.read_csv('data/olives_s2_sampling_data_2019-2020.csv')\n",
    "sampling_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = pd.read_csv('data/ML_sentinel2_training_data_19_20.csv')\n",
    "training_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lists will be populated and will become the values for the dictionary's keys\n",
    "sulabels = []\n",
    "strtypelabels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that will be use to create a dataframe with the new classes in a column\n",
    "labels_dic = {'su':sulabels,'stress_type':strtypelabels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sampling_data)):\n",
    "    if sampling_data.total_stress[i] < 0.06:\n",
    "        labels_dic['su'].append(sampling_data.sampling_unit_codes[i])\n",
    "        labels_dic['stress_type'].append('healthy')\n",
    "    else:\n",
    "        if sampling_data.verticillium[i] >= sampling_data.cycloconium[i] and sampling_data.verticillium[i] > sampling_data.usf[i]:\n",
    "            labels_dic['su'].append(sampling_data.sampling_unit_codes[i])\n",
    "            labels_dic['stress_type'].append('verticillium')\n",
    "        if sampling_data.cycloconium[i] > sampling_data.verticillium[i] and sampling_data.cycloconium[i] > sampling_data.usf[i]:\n",
    "            labels_dic['su'].append(sampling_data.sampling_unit_codes[i])\n",
    "            labels_dic['stress_type'].append('spilocaea')\n",
    "        if sampling_data.usf[i] >= sampling_data.verticillium[i] and sampling_data.usf[i] >= sampling_data.cycloconium[i]:\n",
    "            labels_dic['su'].append(sampling_data.sampling_unit_codes[i])\n",
    "            labels_dic['stress_type'].append('unidentified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the dictionary, created in the previous step, to create a new dataframe\n",
    "labels = pd.DataFrame(labels_dic, columns=['su','stress_type'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is a simple way to add new columns to an existing dataframe\n",
    "sampling_data['stress_type'] = labels['stress_type']\n",
    "sampling_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_data['stress_type'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Merge the data frame containing the labeled data with the one containing the training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = ['NDVI', 'RDVI', 'GNDVI', 'SAVI', 'OSAVI', 'EVI', 'TVI', 'MTVI1',\n",
    "       'TCARI', 'MCARI', 'MSR', 'CARI', 'PSSRb', 'PSSRc', 'TCARI/OSAVI',\n",
    "       'Redness', 'ARVI', 'ARI1', 'ARI2', 'CRI1', 'CRI2', 'B02', 'B03', 'B04', 'B08']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_data[columns_to_add] = training_features[columns_to_add]\n",
    "sampling_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Remove the outliers from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = sampling_data[\"total_stress\"].quantile(0.25)\n",
    "q3 = sampling_data[\"total_stress\"].quantile(0.75)\n",
    "\n",
    "iqr = q3 - q1\n",
    "cut_off = iqr * 1.5\n",
    "\n",
    "lower_threshold = q1 - cut_off\n",
    "upper_threshold = q3 + cut_off\n",
    "\n",
    "sampling_data_clrd = sampling_data[(sampling_data.total_stress > lower_threshold) & (sampling_data.total_stress < upper_threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the indices after removing outliers and check the dataset\n",
    "\n",
    "sampling_data_clrd.reset_index(drop=True, inplace=True)\n",
    "\n",
    "sampling_data_clrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_data_clrd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4.1: Create dummy variables for string columns in **features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4.2: Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_data_clrd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['sampling_unit_codes',\n",
    "           'verticillium',\n",
    "           'cycloconium',\n",
    "           'usf',\n",
    "           'total_stress',\n",
    "           'su_surface',\n",
    "           'su_tree_surface',\n",
    "           'su_background_surface',\n",
    "           'su_veg_percent',\n",
    "           'su_backgr_percent'\n",
    "          ]\n",
    "\n",
    "data = sampling_data_clrd.drop(to_drop, axis=1)\n",
    "data\n",
    "# A different way below, but it raises an issue\n",
    "# sampling_data_clrd.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: Use an oversampling technique to equalize the class samples (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = data.stress_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the ditribution of the classes\n",
    "data.stress_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X would be the following\n",
    "data[data.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and y the following:\n",
    "data.stress_type.to_excel('results\\pathogen_classes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[data.columns[1:]]\n",
    "y = data.stress_type[:]\n",
    "# label encode the target variable\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "# summarize distribution\n",
    "counter = Counter(y_encoded)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(y_encoded) * 100\n",
    "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By default, SMOTE will oversample all classes to have the same number of examples as the class with the most examples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data[data.columns[1:]]\n",
    "# y = data.stress_type[:]\n",
    "\n",
    "# # label encode the target variable\n",
    "# y = LabelEncoder().fit_transform(y)\n",
    "# # transform the dataset\n",
    "# oversample = SMOTE(random_state=0)\n",
    "# X, y = oversample.fit_resample(X, y)\n",
    "# # summarize distribution\n",
    "# counter = Counter(y)\n",
    "# for k,v in counter.items():\n",
    "# \tper = v / len(y) * 100\n",
    "# \tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# # plot the distribution\n",
    "# plt.bar(counter.keys(), counter.values())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6: APPLY CLASSIFICATION ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder().inverse_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneVsRestClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The classifier that provided the best accuracy for general stress detection was quadratic_discriminant when applied to infection threshold 6% on vegetation surface to classify as stressed, with the parameters given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as qda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneVsRestClassifier?\n",
    "\n",
    "# load feature and label data on variables\n",
    "X, y = data[data.columns[1:]], data.stress_type[:]\n",
    "\n",
    "# transform the label categories (healthy, vert, cyclo, usf) to numerical class digits (class 1, class 2 etc.)\n",
    "# y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# define and apply the oversampling technique to the entire dataset\n",
    "oversample = SMOTE(random_state=0)\n",
    "X_sm, y_sm = oversample.fit_resample(X, y)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sm_enc = LabelEncoder().fit_transform(y_sm)\n",
    "# summarize distribution after oversampling with SMOTE\n",
    "counter = Counter(y_sm_enc)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(y_sm_enc) * 100\n",
    "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data in training and test sets\n",
    "X_train, X_test, y_train, y_test = skl.train_test_split(X_sm, y_sm, test_size=0.25, random_state=0)\n",
    "\n",
    "# define the classifier to be used as clf\n",
    "clf = OneVsRestClassifier(qda(\n",
    "    reg_param=0.0,\n",
    "    store_covariance=True,\n",
    "    tol=0.001\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training data in the classifier and get the predicted values by applying the classifier to the test set\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "ax.set_title('OvR Confusion Matrix\\n', fontsize=20)\n",
    "ax.set_xlabel('\\nPredicted label', fontsize=16)\n",
    "ax.set_ylabel('True label', fontsize=16)\n",
    "for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "\tlabel.set_fontsize(14)\n",
    "\n",
    "\n",
    "plt.grid(False)\n",
    "skm.plot_confusion_matrix(clf, X_test, y_test, cmap='bone',ax=ax)\n",
    "# skm.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('D:\\Dropbox\\Publications\\sentinel-2 olive tree stress detection\\Results & Discussion\\\\figures\\conf_matrix_20221001.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_cm = skm.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "multiclass_cm_df = pd.DataFrame(multiclass_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,7))\n",
    "hm = sns.heatmap(multiclass_cm_df, annot=True,cmap=\"Greys\")\n",
    "hm.xaxis.set_ticklabels(hm.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=14)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7: ACQUIRE VISUALIZATIONS AND METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Create Functions to calculate tpr, fpr, roc coords and plot the roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tpr_fpr(y_real, y_pred):\n",
    "    '''\n",
    "    Calculates the True Positive Rate (tpr) and the True Negative Rate (fpr) based on real and predicted observations\n",
    "    \n",
    "    Args:\n",
    "        y_real: The list or series with the real classes\n",
    "        y_pred: The list or series with the predicted classes\n",
    "        \n",
    "    Returns:\n",
    "        tpr: The True Positive Rate of the classifier\n",
    "        fpr: The False Positive Rate of the classifier\n",
    "    '''\n",
    "    \n",
    "    # Calculates the confusion matrix and recover each element\n",
    "    cm = confusion_matrix(y_real, y_pred)\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "    TP = cm[1, 1]\n",
    "    \n",
    "    # Calculates tpr and fpr\n",
    "    tpr =  TP/(TP + FN) # sensitivity - true positive rate\n",
    "    fpr = 1 - TN/(TN+FP) # 1-specificity - false positive rate\n",
    "    \n",
    "    return tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_roc_coordinates(y_real, y_proba):\n",
    "    '''\n",
    "    Calculates all the ROC Curve coordinates (tpr and fpr) by considering each point as a treshold for the predicion of the class.\n",
    "    \n",
    "    Args:\n",
    "        y_real: The list or series with the real classes.\n",
    "        y_proba: The array with the probabilities for each class, obtained by using the `.predict_proba()` method.\n",
    "        \n",
    "    Returns:\n",
    "        tpr_list: The list of TPRs representing each threshold.\n",
    "        fpr_list: The list of FPRs representing each threshold.\n",
    "    '''\n",
    "    tpr_list = [0]\n",
    "    fpr_list = [0]\n",
    "    for i in range(len(y_proba)):\n",
    "        threshold = y_proba[i]\n",
    "        y_pred = y_proba >= threshold\n",
    "        tpr, fpr = calculate_tpr_fpr(y_real, y_pred)\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "    return tpr_list, fpr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(tpr, fpr, scatter = True, ax = None):\n",
    "    '''\n",
    "    Plots the ROC Curve by using the list of coordinates (tpr and fpr).\n",
    "    \n",
    "    Args:\n",
    "        tpr: The list of TPRs representing each coordinate.\n",
    "        fpr: The list of FPRs representing each coordinate.\n",
    "        scatter: When True, the points used on the calculation will be plotted with the line (default = True).\n",
    "    '''\n",
    "    if ax == None:\n",
    "        plt.figure(figsize = (5, 5))\n",
    "        ax = plt.axes()\n",
    "    \n",
    "    if scatter:\n",
    "        sns.scatterplot(x = fpr, y = tpr, ax = ax)\n",
    "    sns.lineplot(x = fpr, y = tpr, ax = ax)\n",
    "    sns.lineplot(x = [0, 1], y = [0, 1], color = 'green', ax = ax)\n",
    "    plt.xlim(-0.05, 1.05)\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the Probability Distributions and the ROC Curves One vs Rest\n",
    "fig2 = plt.figure(figsize = (12, 8))\n",
    "bins = [i/20 for i in range(20)] + [1]\n",
    "classes = clf.classes_\n",
    "roc_auc_ovr = {}\n",
    "for i in range(len(classes)):\n",
    "    # Gets the class\n",
    "    c = classes[i]\n",
    "    \n",
    "    # Prepares an auxiliar dataframe to help with the plots\n",
    "    df_aux = X_test.copy()\n",
    "    df_aux['class'] = [1 if y == c else 0 for y in y_test]\n",
    "    df_aux['prob'] = y_proba[:, i]\n",
    "    df_aux = df_aux.reset_index(drop = True)\n",
    "    \n",
    "    # Plots the probability distribution for the class and the rest\n",
    "    ax = plt.subplot(2, 4, i+1) # 2 is for the number of rows, 4 for the number of classes and i+1 to start plotting a specific plot starting from 1 for the top left\n",
    "    sns.histplot(x = \"prob\", data = df_aux, hue = 'class', color = 'b', ax = ax, bins = bins)\n",
    "    ax.set_title(c)\n",
    "    ax.legend([f\"Class: {c}\", \"Rest\"])\n",
    "    ax.set_xlabel(f\"P(x = {c})\")\n",
    "    \n",
    "    # Calculates the ROC Coordinates and plots the ROC Curves\n",
    "    ax_bottom = plt.subplot(2, 4, i+5) # i+5 is to skip the first four plots, and apply the subplot on the fifth\n",
    "    tpr, fpr = get_all_roc_coordinates(df_aux['class'], df_aux['prob'])\n",
    "    plot_roc_curve(tpr, fpr, scatter = False, ax = ax_bottom)\n",
    "    ax_bottom.set_title(\"ROC Curve OvR\")\n",
    "    \n",
    "    # Calculates the ROC AUC OvR\n",
    "    roc_auc_ovr[c] = skm.roc_auc_score(df_aux['class'], df_aux['prob'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2.savefig('D:\\Dropbox\\Publications\\sentinel-2 olive tree stress detection\\Results & Discussion\\\\figures\\ovr_class_comparison_20221001.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Acquire metrics for the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the ROC AUC for each class\n",
    "avg_roc_auc = 0\n",
    "i = 0\n",
    "for k in roc_auc_ovr:\n",
    "    avg_roc_auc += roc_auc_ovr[k]\n",
    "    i += 1\n",
    "    print(f\"{k} ROC AUC OvR: {roc_auc_ovr[k]:.4f}\")\n",
    "print(f\"average ROC AUC OvR: {avg_roc_auc/i:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = skm.accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(skm.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.catplot(x=\"stress_type\", y=\"total_stress\", data=sampling_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(sampling_data.total_stress, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,8))\n",
    "# plt.grid(False)\n",
    "sns.scatterplot(data=sampling_data_clrd, y=\"su_veg_percent\", x=\"total_stress\", hue=\"stress_type\", s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(16,8))\n",
    "\n",
    "# sns.lineplot(data=sampling_data, x=\"su_veg_percent\", y=\"total_stress\")\n",
    "sns.lineplot(data=sampling_data_clrd, x=\"su_veg_percent\", y=\"NDVI\", hue=\"stress_type\")\n",
    "# sns.lineplot(data=sampling_data, x=\"su_backgr_percent\", y=\"total_stress\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_data_clrd.columns"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
